Bias, Variance, and Error Correcting Output Codes for Local Learners : This paper focuses on a bias variance decomposition analysis of a local learning algorithm, the nearest neighbor classifier, that has been extended with error correcting output codes. This extended algorithm often considerably reduces the 0-1 (i.e., classification) error in comparison with nearest neighbor (Ricci & Aha, 1997). The analysis presented here reveals that this performance improvement is obtained by drastically reducing bias at the cost of increasing variance. We also show that, even in classification problems with few classes (m5), extending the codeword length beyond the limit that assures column separation yields an error reduction. This error reduction is not only in the variance, which is due to the voting mechanism used for error-correcting output codes, but also in the bias. Keywords: Case-based learning, classification, error-correcting output codes, bias and variance Email: ricci@irst.itc.it, aha@aic.nrl.navy.mil Phone: ++39 461 314334 FAX: ++39 461 302040 Bi...
