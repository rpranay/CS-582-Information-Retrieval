Vision-Based User Interface for Interacting with a Virtual Environment Abstract. This paper proposes a new and natural human computer interface for interacting with virtual environments. The 3D pointing direction of a user in a virtual environment is estimated using monocular computer vision. The 2D position of the user???s hand is extracted in the image plane and then mapped to a 3D direction using knowledge about the position of the user???s head and kinematic constraints of a pointing gesture due to the human motor system. Off-line tests of the system show promising results. The implementation of a real time system is currently in progress and is expected to run with 25Hz. 1
