A Multimodal Approach To Term Extraction Using A Rhetorical Structure Theory Tagger And Formal Concept Analysis This paper reports on knowledge extraction using Rhetorical Structure Theory (RST) and Formal Concept Analysis (FCA). The research is multimodal in two ways: (i) it uses a text tagger to identify key terms in free text, these terms are then used as indexation filters over the free text; (ii) it aims to normalise the contents of multiple text sources into a single knowledge base. The aim is semi-automated extraction of semantic content in texts derived from different sources and merging them into a single coherent knowledge base. We use RST ([7]) to automate the identification of discourse markers in multiple texts dealing with a single subject matter. Marcu ([8, 10]) has shown that RST can be used for the semiautomated mark up of natural language texts. Marcu uses discourse trees, useful to store information about the rhetorical structure, and has shown that the identification of discourse markers from prototypical texts can be automated with 88% precision ([9]). We have adapted Marcu's algorithm in our approach. Although our work draws on recent results from natural language processing, progress in that field is not the objective. The research is motivated by the analysis of texts generated by different sources, their translation to a formal knowledge representation followed by a consolidation into a single knowledge corpus. Our interest is in the analysis of this corpus to determine the reliability of information obtained from multiple agencies ([11]) and then to visually navigate this knowledge. This involves FCA ([14, 15, 17, 18, 6]) for browsing and retrieving text documents ([2, 3, 4, 1]). FCA is typically a propositional knowledge representation technique, i.e., it can only express monadic relations. Recently, Wille ([16]) has shown that FCA can be used to repres...
