A Natural Interface to a Virtual Environment through Computer Vision-estimated Pointing Gestures . This paper describes the development of a natural interface to a virtual  environment. The interface is through a natural pointing gesture and replaces  pointing devices which are normally used to interact with virtual environments.  The pointing gesture is estimated in 3D using kinematic knowledge of the arm  during pointing and monocular computer vision. The latter is used to extract the  2D position of the user's hand and map it into 3D. Off-line tests of the system  show promising results with an average errors of 76mm when pointing at a screen  2m away. The implementation of a real time system is currently in progress and  is expected to run with 25Hz.  1 
