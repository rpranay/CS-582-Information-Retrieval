Direct value-approximation for factored MDPs We present a simple approach for computing reasonable policies  for factored Markov decision processes (MDPs), when the optimal  value function can be approximated by a compact linear form.
